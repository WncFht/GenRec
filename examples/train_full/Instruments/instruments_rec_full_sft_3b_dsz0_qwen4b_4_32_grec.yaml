### model
model_name_or_path: /mnt/dolphinfs/hdd_pool/docker/user/hadoop-hmart-poistar/fanghaotian/ckpt/base_model/Qwen2.5-3B-Instruct
trust_remote_code: true
add_tokens_list: 'data/Instruments_grec_index_emb-qwen3-embedding-4B_rq4_cb32-32-32-32_dsInstruments_ridFeb-10-2026-05-52-11/new_tokens.json'
### method
stage: sft
do_train: true
finetuning_type: full
deepspeed: examples/deepspeed/ds_z0_config.json

### dataset
dataset: Instruments_grec_index_emb_qwen3_embedding_4B_rq4_cb32_32_32_32_dsInstruments_ridFeb_10_2026_05_52_11_train
cutoff_len: 512
preprocessing_num_workers: 16
dataloader_num_workers: 4

### output
output_dir: saves/qwen2.5-3b/full/Instruments-grec-sft-qwen4B-4-32-dsz0
logging_steps: 1
save_steps: 0.05
plot_loss: true
overwrite_output_dir: true
save_only_model: false
save_strategy: steps
load_best_model_at_end: true
save_total_limit: 2
### experiment
report_to: wandb
run_name: Instruments-grec-qwen2.5-3b-sft-qwen4B-4-32-dsz0

### train
per_device_train_batch_size: 32
gradient_accumulation_steps: 16
learning_rate: 3.0e-4
num_train_epochs: 10.0
lr_scheduler_type: cosine

warmup_steps: 20
bf16: true
ddp_timeout: 180000000
resume_from_checkpoint: null
early_stopping_steps: 3
metric_for_best_model: loss


### eval
eval_dataset: Instruments_grec_index_emb_qwen3_embedding_4B_rq4_cb32_32_32_32_dsInstruments_ridFeb_10_2026_05_52_11_valid
per_device_eval_batch_size: 32
eval_strategy: steps
eval_steps: 0.05
